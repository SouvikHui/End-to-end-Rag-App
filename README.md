# 🧠 Online Article Analyzer (RAG-based)
### A lightweight full-stack [FastAPI (backend) + Streamlit (frontend)] Question-Answering (QA) system that allows users to input up to 5 article URLs, YouTube links, or attach PDF, DOCX, TXT, or audio files. For YouTube links and audio files, transcription is handled using the `whisper-large-v3-turbo` model via the Groq API. The fetched content is embedded using Nomic Embeddings, and context-aware answers are generated via the Groq LLM (`LLaMA-3.3-70B (Versatile)`). The app uses FAISS for fast vector search and LangChain to orchestrate the Retrieval-Augmented Generation (RAG) pipeline.

## ✨ Features

- 🔗 Accepts multiple **article URLs** (1 to 5)
- ▶️ Accepts **YouTube video links** for QA (audio transcribed using `whisper-large-v3-turbo`)
- 🔊 Supports **audio file uploads** (e.g., .mp3, .wav) for QA
- 📄 Extracts and chunks content (text, audio transcripts)
- 🧠 Embeds using **Nomic Embeddings**
- 💬 Ask context-specific questions
- ⚡️ Answers generated by **Groq LLaMA-3.3-70B (Versatile)**
- 🗂️ Uses **FAISS** for local vector storage
- 🚀 Built using **FastAPI (backend)** and **Streamlit (frontend)**


| Layer       | Technology                          |
|-------------|-------------------------------------|
| Frontend    | Streamlit UI                        |
| Backend     | FastAPI + LangChain                 |
| Embeddings  | Nomic Embeddings                    |
| Vector DB   | FAISS (local)                       |
|Transcription| Groq API (whisper-large-v3-turbo)   |
| LLM         | Groq API (LLaMA-3.3-70B (Versatile))|
| Loader      | Pypdf, BeautifulSoup, yt_dlp        |

## 📁 Project Structure
<details>
<summary>📁 Click to expand project structure</summary>

```
project-root/
│
├── backend/
│   ├── main.py # FastAPI server
│   ├── models.py # Pydantic schemas
│   ├── fetcher.py # URL & attached file (.pdf,.docx,.txt) loader
|   ├── yt_audio_fetcher.py # YT link & attched audio handling & transcription 
│   ├── embed_data.py # Embedding logic
│   ├── rag_qa.py # RAG QA pipeline
│   └── faiss_store/ # Saved FAISS index (Auto-created on app run)
│
├── frontend/
│   └── app.py # Streamlit frontend
│
├── .env # Your API keys (GROQ_API_KEY, NOMIC_API_KEY)
├── requirements.txt
└── README.md
```
</details>

## ⚙️ Setup Instructions
1. Clone the Repository:
  ```git clone https://github.com/SouvikHui/End-to-end-Rag-App.git```
  ```cd End-to-end-Rag-App```

2. Create and Activate Environment:
  ```conda create -n ragenv python=3.11.5```
  ```conda activate ragenv```

3. Install Dependencies:
```pip install -r requirements.txt```
    Include dependencies like: fastapi, uvicorn, streamlit, pypdf, yt-dlp, langchain, langchain_groq, langchain_community, python-dotenv, requests, etc.
4. Set Up Environment Variables
**Create a .env file in the root directory:
  GROQ_API_KEY=your_groq_api_key
  NOMIC_API_KEY=your_nomic_api_key

## ▶️ Running the App
1. Start Backend (FastAPI):
```uvicorn backend.main:app --reload```
By default, the backend runs at: http://localhost:8000
otherwise, use ```uvicorn backend.main:app --reload --host 127.0.0.1 --port 8000```
2. Start Frontend (Streamlit):
```streamlit run frontend/app.py```

## 🧪 Example Usage
1. Paste 1–5 article URLs.
2. Or upload a file from local machine (PDF/DOCX/TXT)
3. Or input a YouTube video link (will transcribe audio)
4. Or upload an audio file (MP3/WAV)
5. Click “Process Articles”.
6. Ask questions about the content.
7. Get answers retrieved from the embedded article context.

## 📌 Coming Soon
- 📊 .xls/.xlsx file support for tabular QA
- 🧾 Multiple attachment file support (multi-document QA)
- 🗣️ Speaker diarization for meetings
- 🧠 Multi-agent LLM QA chains
